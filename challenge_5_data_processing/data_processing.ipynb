{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId             title                                       genres  \\\n",
      "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "1        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "2        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "3        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "4        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "\n",
      "   userId  rating   timestamp  imdbId  tmdbId  \n",
      "0       1     4.0   964982703  114709   862.0  \n",
      "1       5     4.0   847434962  114709   862.0  \n",
      "2       7     4.5  1106635946  114709   862.0  \n",
      "3      15     2.5  1510577970  114709   862.0  \n",
      "4      17     4.5  1305696483  114709   862.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pandas\n",
    "# Load the movies dataset\n",
    "movies = pd.read_csv('movies.csv')\n",
    "\n",
    "# Load the ratings dataset\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "\n",
    "# Load the links dataset\n",
    "links = pd.read_csv('links.csv')\n",
    "\n",
    "# Merge the datasets based on movieId\n",
    "merged_data = pd.merge(movies, ratings, on='movieId')\n",
    "merged_data = pd.merge(merged_data, links, on='movieId')\n",
    "\n",
    "# Display the first few rows of the merged dataset\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average ratings:\n",
      "title\n",
      "'71 (2014)                                   4.000000\n",
      "'Hellboy': The Seeds of Creation (2004)      4.000000\n",
      "'Round Midnight (1986)                       3.500000\n",
      "'Salem's Lot (2004)                          5.000000\n",
      "'Til There Was You (1997)                    4.000000\n",
      "                                               ...   \n",
      "eXistenZ (1999)                              3.863636\n",
      "xXx (2002)                                   2.770833\n",
      "xXx: State of the Union (2005)               2.000000\n",
      "¡Three Amigos! (1986)                        3.134615\n",
      "À nous la liberté (Freedom for Us) (1931)    1.000000\n",
      "Name: rating, Length: 9719, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the average rating for each movie\n",
    "average_ratings = merged_data.groupby('title')['rating'].mean()\n",
    "print(\"\\nAverage ratings:\")\n",
    "print(average_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Max ratings by genre:\n",
      "genres\n",
      "(no genres listed)                     5.0\n",
      "Action                                 5.0\n",
      "Action|Adventure                       5.0\n",
      "Action|Adventure|Animation             5.0\n",
      "Action|Adventure|Animation|Children    5.0\n",
      "                                      ... \n",
      "Sci-Fi|Thriller                        5.0\n",
      "Sci-Fi|Thriller|IMAX                   4.5\n",
      "Thriller                               5.0\n",
      "War                                    5.0\n",
      "Western                                5.0\n",
      "Name: rating, Length: 951, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the maximum rating for each genre\n",
    "max_ratings_by_genre = merged_data.groupby('genres')['rating'].max()\n",
    "print(\"\\nMax ratings by genre:\")\n",
    "print(max_ratings_by_genre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highly rated movies:\n",
      "        movieId                             title  \\\n",
      "9             1                  Toy Story (1995)   \n",
      "12            1                  Toy Story (1995)   \n",
      "13            1                  Toy Story (1995)   \n",
      "16            1                  Toy Story (1995)   \n",
      "19            1                  Toy Story (1995)   \n",
      "...         ...                               ...   \n",
      "100787   187593                 Deadpool 2 (2018)   \n",
      "100790   187593                 Deadpool 2 (2018)   \n",
      "100791   187593                 Deadpool 2 (2018)   \n",
      "100801   187595    Solo: A Star Wars Story (2018)   \n",
      "100802   187717  Won't You Be My Neighbor? (2018)   \n",
      "\n",
      "                                             genres  userId  rating  \\\n",
      "9       Adventure|Animation|Children|Comedy|Fantasy      31     5.0   \n",
      "12      Adventure|Animation|Children|Comedy|Fantasy      40     5.0   \n",
      "13      Adventure|Animation|Children|Comedy|Fantasy      43     5.0   \n",
      "16      Adventure|Animation|Children|Comedy|Fantasy      46     5.0   \n",
      "19      Adventure|Animation|Children|Comedy|Fantasy      57     5.0   \n",
      "...                                             ...     ...     ...   \n",
      "100787                         Action|Comedy|Sci-Fi      98     5.0   \n",
      "100790                         Action|Comedy|Sci-Fi     249     5.0   \n",
      "100791                         Action|Comedy|Sci-Fi     305     5.0   \n",
      "100801             Action|Adventure|Children|Sci-Fi     586     5.0   \n",
      "100802                                  Documentary     462     5.0   \n",
      "\n",
      "         timestamp   imdbId    tmdbId  \n",
      "9        850466616   114709     862.0  \n",
      "12       832058959   114709     862.0  \n",
      "13       848993983   114709     862.0  \n",
      "16       834787906   114709     862.0  \n",
      "19       965796031   114709     862.0  \n",
      "...            ...      ...       ...  \n",
      "100787  1532457913  5463162  383498.0  \n",
      "100790  1531611534  5463162  383498.0  \n",
      "100791  1532877841  5463162  383498.0  \n",
      "100801  1529899556  3778644  348350.0  \n",
      "100802  1529413865  7681902  490003.0  \n",
      "\n",
      "[13211 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataset to only include movies with a rating above 4.5\n",
    "highly_rated_movies = merged_data[merged_data['rating'] > 4.5]\n",
    "print(\"\\nHighly rated movies:\")\n",
    "print(highly_rated_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 64534\n",
      "Validation set size: 16134\n",
      "Testing set size: 20168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Scikit-learn\n",
    "# Split the merged dataset into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(merged_data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the sizes of the resulting sets\n",
    "print(\"Training set size:\", len(train_data))\n",
    "print(\"Validation set size:\", len(val_data))\n",
    "print(\"Testing set size:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['num_genres', 'year'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Thobeka Silume\\Documents\\Xolani\\helm_technical_challenge\\challenge_5_data_processing\\data_processing.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Thobeka%20Silume/Documents/Xolani/helm_technical_challenge/challenge_5_data_processing/data_processing.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Split the dataset into features (X) and target variable (y)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Thobeka%20Silume/Documents/Xolani/helm_technical_challenge/challenge_5_data_processing/data_processing.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X \u001b[39m=\u001b[39m merged_data[[\u001b[39m\"\u001b[39;49m\u001b[39mnum_genres\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39myear\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Thobeka%20Silume/Documents/Xolani/helm_technical_challenge/challenge_5_data_processing/data_processing.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y \u001b[39m=\u001b[39m merged_data[\u001b[39m\"\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Thobeka%20Silume/Documents/Xolani/helm_technical_challenge/challenge_5_data_processing/data_processing.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Split the dataset into training and test sets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thobeka Silume\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:3902\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3900\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3901\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3902\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3904\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Thobeka Silume\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6116\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6118\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thobeka Silume\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6175\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6173\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6174\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 6175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6177\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   6178\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['num_genres', 'year'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = merged_data[[\"num_genres\", \"year\"]]\n",
    "y = merged_data[\"rating\"]\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using linear regression\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# Evaluate the linear regression model using mean squared error\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "print(\"Linear Regression Mean Squared Error:\", mse_lr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helm_technical_challenge-OkjyDm5i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
